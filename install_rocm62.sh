#!/bin/bash

# TxAgent ROCm 6.2 å¿«é€Ÿå®‰è£…è„šæœ¬
# ä¸“ä¸ºå·²å®‰è£… ROCm 6.2 çš„çŽ¯å¢ƒä¼˜åŒ–

echo "ðŸš€ å¼€å§‹å®‰è£… TxAgent (ROCm 6.2)..."

# æ£€æŸ¥ ROCm 6.2
echo "ðŸ“‹ æ£€æŸ¥ ROCm 6.2 çŽ¯å¢ƒ..."
if command -v rocm-smi &> /dev/null; then
    echo "âœ… ROCm å·²å®‰è£…"
    rocm_version=$(rocm-smi --showproductname | head -1)
    echo "ROCm ä¿¡æ¯: $rocm_version"
    rocm-smi
else
    echo "âŒ ROCm æœªæ£€æµ‹åˆ°ï¼Œè¯·ç¡®è®¤å®‰è£…"
    exit 1
fi

# è®¾ç½® ROCm 6.2 çŽ¯å¢ƒå˜é‡
echo "ðŸ”§ è®¾ç½® ROCm 6.2 çŽ¯å¢ƒå˜é‡..."
export ROCM_PATH=/opt/rocm
export HIP_PATH=/opt/rocm
export HSA_PATH=/opt/rocm
export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH
export PATH=/opt/rocm/bin:$PATH

# MI300X ç‰¹å®šè®¾ç½®
export PYTORCH_ROCM_ARCH="gfx942"  # MI300X
export HIP_VISIBLE_DEVICES=0
export HSA_FORCE_FINE_GRAIN_PCIE=1
export HIP_FORCE_DEV_KERNARG=1

# vLLM å’Œ TxAgent ä¼˜åŒ–
export VLLM_USE_V1=0
export TOKENIZERS_PARALLELISM=false
export MKL_THREADING_LAYER=GNU

echo "çŽ¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ"

# å‡çº§ pip
echo "ðŸ“¦ å‡çº§ pip..."
pip install --upgrade pip setuptools wheel

# å®‰è£… Rustï¼ˆè§£å†³ outlines_core ç¼–è¯‘é—®é¢˜ï¼‰
echo "ðŸ¦€ æ£€æŸ¥ Rust..."
if ! command -v rustc &> /dev/null; then
    echo "å®‰è£… Rust..."
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
    source ~/.cargo/env
    echo "âœ… Rust å®‰è£…å®Œæˆ"
else
    echo "âœ… Rust å·²å®‰è£…: $(rustc --version)"
fi

# å®‰è£… PyTorch ROCm 6.2 ç‰ˆæœ¬
echo "ðŸ”¥ å®‰è£… PyTorch ROCm 6.2 ç‰ˆæœ¬..."
pip uninstall -y torch torchvision torchaudio  # æ¸…ç†æ—§ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2

# éªŒè¯ PyTorch å®‰è£…
echo "ðŸ” éªŒè¯ PyTorch å®‰è£…..."
python -c "
import torch
print(f'PyTorch ç‰ˆæœ¬: {torch.__version__}')
print(f'ROCm ç¼–è¯‘ç‰ˆæœ¬: {torch.version.hip if hasattr(torch.version, \"hip\") else \"æœªçŸ¥\"}')
print(f'CUDA å¯ç”¨ (å®žé™…æ˜¯ROCm): {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}')
        
    # ç®€å•çš„ GPU æµ‹è¯•
    try:
        x = torch.randn(100, 100).cuda()
        y = torch.mm(x, x.t())
        print('âœ… GPU è®¡ç®—æµ‹è¯•æˆåŠŸ')
        del x, y
        torch.cuda.empty_cache()
    except Exception as e:
        print(f'âŒ GPU è®¡ç®—æµ‹è¯•å¤±è´¥: {e}')
else:
    print('âŒ GPU ä¸å¯ç”¨')
"

# å®‰è£…åŸºç¡€ä¾èµ–
echo "ðŸ“š å®‰è£…åŸºç¡€ä¾èµ–..."
pip install numpy jinja2 typing-extensions
pip install transformers>=4.30.0
pip install accelerate>=0.20.0
pip install sentence-transformers
pip install gradio

# å®‰è£… TxAgentï¼ˆè·³è¿‡ä¾èµ–æ£€æŸ¥é¿å…å†²çªï¼‰
echo "ðŸ¤– å®‰è£… TxAgent..."
pip install -e . --no-deps

# å®‰è£… ToolUniverse
echo "ðŸ› ï¸ å®‰è£… ToolUniverse..."
pip install tooluniverse

# å®‰è£… vLLMï¼ˆROCm 6.2 å…¼å®¹ç‰ˆæœ¬ï¼‰
echo "âš¡ å®‰è£… vLLM..."
# å¯¹äºŽ ROCm 6.2ï¼Œä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ vLLM
pip install vllm --no-build-isolation || {
    echo "âš ï¸  æ ‡å‡†å®‰è£…å¤±è´¥ï¼Œå°è¯•æ— ç¼“å­˜å®‰è£…..."
    pip install vllm --no-cache-dir --no-build-isolation || {
        echo "âš ï¸  vLLM å®‰è£…å¤±è´¥ï¼Œå°è¯•ä»Žæºç å®‰è£…..."
        pip install git+https://github.com/vllm-project/vllm.git --no-build-isolation || {
            echo "âŒ vLLM å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¤„ç†"
        }
    }
}

# ä¿å­˜çŽ¯å¢ƒå˜é‡åˆ°æ–‡ä»¶
echo "ðŸ’¾ ä¿å­˜çŽ¯å¢ƒé…ç½®..."
cat > ~/.txagent_rocm62_env << 'EOF'
# TxAgent ROCm 6.2 çŽ¯å¢ƒå˜é‡
export ROCM_PATH=/opt/rocm
export HIP_PATH=/opt/rocm
export HSA_PATH=/opt/rocm
export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH
export PATH=/opt/rocm/bin:$PATH

# MI300X ä¼˜åŒ–
export PYTORCH_ROCM_ARCH="gfx942"
export HIP_VISIBLE_DEVICES=0
export HSA_FORCE_FINE_GRAIN_PCIE=1
export HIP_FORCE_DEV_KERNARG=1

# TxAgent ä¼˜åŒ–
export VLLM_USE_V1=0
export TOKENIZERS_PARALLELISM=false
export MKL_THREADING_LAYER=GNU

# å†…å­˜ä¼˜åŒ–
export PYTORCH_HIP_ALLOC_CONF=max_split_size_mb:128
export HIP_LAUNCH_BLOCKING=0
EOF

echo "çŽ¯å¢ƒå˜é‡å·²ä¿å­˜åˆ° ~/.txagent_rocm62_env"

# æœ€ç»ˆéªŒè¯
echo "âœ… æœ€ç»ˆéªŒè¯..."
source ~/.txagent_rocm62_env

python -c "
print('ðŸ” éªŒè¯å®‰è£…çŠ¶æ€...')

# æ£€æŸ¥ TxAgent
try:
    from txagent import TxAgent
    print('âœ… TxAgent å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ TxAgent å¯¼å…¥å¤±è´¥: {e}')

# æ£€æŸ¥ ToolUniverse
try:
    from tooluniverse import ToolUniverse
    print('âœ… ToolUniverse å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ ToolUniverse å¯¼å…¥å¤±è´¥: {e}')

# æ£€æŸ¥ vLLM
try:
    import vllm
    print(f'âœ… vLLM å¯¼å…¥æˆåŠŸ: {vllm.__version__}')
except ImportError as e:
    print(f'âŒ vLLM å¯¼å…¥å¤±è´¥: {e}')

# GPU æµ‹è¯•
try:
    import torch
    if torch.cuda.is_available():
        print('âœ… GPU å¯ç”¨')
        device_name = torch.cuda.get_device_name(0)
        print(f'GPU è®¾å¤‡: {device_name}')
        
        # å†…å­˜æµ‹è¯•
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f'GPU å†…å­˜ - å·²åˆ†é…: {allocated:.2f}GB, å·²ä¿ç•™: {reserved:.2f}GB')
        
    else:
        print('âŒ GPU ä¸å¯ç”¨')
except Exception as e:
    print(f'âŒ GPU æ£€æŸ¥å¤±è´¥: {e}')
"

echo ""
echo "ðŸŽ‰ å®‰è£…å®Œæˆï¼"
echo ""
echo "ðŸ“ ä½¿ç”¨è¯´æ˜Žï¼š"
echo "1. åŠ è½½çŽ¯å¢ƒ: source ~/.txagent_rocm62_env"
echo "2. è¿è¡Œæµ‹è¯•: python run_example.py"
echo ""
echo "ðŸ”§ å¦‚æžœé‡åˆ°é—®é¢˜ï¼š"
echo "- æ£€æŸ¥ GPU: rocm-smi"
echo "- æ£€æŸ¥ PyTorch: python -c 'import torch; print(torch.cuda.is_available())'"
echo "- é‡æ–°åŠ è½½çŽ¯å¢ƒ: source ~/.txagent_rocm62_env"
echo ""
echo "ðŸ’¡ MI300X ä¼˜åŒ–å·²å¯ç”¨ï¼ŒåŒ…æ‹¬ï¼š"
echo "- gfx942 æž¶æž„æ”¯æŒ"
echo "- å†…å­˜ä¼˜åŒ–é…ç½®"
echo "- vLLM ROCm 6.2 å…¼å®¹æ€§"
