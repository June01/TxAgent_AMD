# TxAgent AMD GPU æ•…éšœæ’é™¤æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£… ROCm é©±åŠ¨
```bash
# Ubuntu/Debian
wget https://repo.radeon.com/amdgpu-install/latest/ubuntu/jammy/amdgpu-install_5.7.50700-1_all.deb
sudo dpkg -i amdgpu-install_5.7.50700-1_all.deb
sudo amdgpu-install --usecase=rocm

# é‡å¯ç³»ç»Ÿ
sudo reboot
```

### 2. éªŒè¯ ROCm å®‰è£…
```bash
# æ£€æŸ¥ ROCm ç‰ˆæœ¬
rocm-smi
/opt/rocm/bin/rocminfo

# æ£€æŸ¥ GPU è®¾å¤‡
lspci | grep -i amd
```

### 3. å®‰è£… TxAgent AMD ç‰ˆæœ¬
```bash
# ä½¿ç”¨æä¾›çš„å®‰è£…è„šæœ¬
chmod +x install_amd_gpu.sh
./install_amd_gpu.sh

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
pip install -e .
```

## ğŸ”§ å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜1: `outlines_core` ç¼–è¯‘å¤±è´¥
**é”™è¯¯ä¿¡æ¯**: `error: can't find Rust compiler`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£… Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env

# é‡æ–°å®‰è£…
pip install --upgrade pip
pip install outlines_core --no-cache-dir
```

### é—®é¢˜2: PyTorch æ— æ³•è¯†åˆ« AMD GPU
**é”™è¯¯ä¿¡æ¯**: `torch.cuda.is_available()` è¿”å› `False`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $ROCM_PATH
echo $HIP_PATH

# è®¾ç½®ç¯å¢ƒå˜é‡
export ROCM_PATH=/opt/rocm
export HIP_PATH=/opt/rocm
export LD_LIBRARY_PATH=/opt/rocm/lib:$LD_LIBRARY_PATH

# é‡æ–°å®‰è£… PyTorch ROCm ç‰ˆæœ¬
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

### é—®é¢˜3: vLLM ä¸æ”¯æŒ ROCm
**é”™è¯¯ä¿¡æ¯**: vLLM ç›¸å…³çš„ CUDA é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ vLLM ROCm æ”¯æŒ
pip install vllm --no-build-isolation

# å¦‚æœä»æœ‰é—®é¢˜ï¼Œä»æºç ç¼–è¯‘
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e . --no-build-isolation
```

### é—®é¢˜4: å†…å­˜ä¸è¶³é”™è¯¯
**é”™è¯¯ä¿¡æ¯**: `CUDA out of memory` æˆ–ç±»ä¼¼é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨ä»£ç ä¸­æ·»åŠ å†…å­˜ä¼˜åŒ–
import os
os.environ['PYTORCH_HIP_ALLOC_CONF'] = 'max_split_size_mb:128'

# æˆ–è€…å‡å°‘æ¨¡å‹å¤§å°/æ‰¹å¤„ç†å¤§å°
agent = TxAgent(
    model_name,
    rag_model_name,
    enable_summary=False,
    avoid_repeat=False
)
```

### é—®é¢˜5: æ€§èƒ½è¾ƒæ…¢
**è§£å†³æ–¹æ¡ˆ**:
```bash
# è®¾ç½®æ€§èƒ½ä¼˜åŒ–ç¯å¢ƒå˜é‡
export HSA_FORCE_FINE_GRAIN_PCIE=1
export HIP_FORCE_DEV_KERNARG=1
export PYTORCH_ROCM_ARCH=gfx906;gfx908;gfx90a;gfx1030;gfx1100

# ä½¿ç”¨é…ç½®è„šæœ¬
python amd_gpu_config.py
```

## ğŸ” è°ƒè¯•å·¥å…·

### æ£€æŸ¥ GPU çŠ¶æ€
```bash
# ROCm ç³»ç»Ÿç›‘æ§
rocm-smi

# è¯¦ç»† GPU ä¿¡æ¯
rocminfo

# å†…å­˜ä½¿ç”¨æƒ…å†µ
rocm-smi --showmeminfo
```

### Python è°ƒè¯•ä»£ç 
```python
import torch
from src.txagent.gpu_utils import print_gpu_info

# æ‰“å° GPU ä¿¡æ¯
print_gpu_info()

# æµ‹è¯• GPU è®¡ç®—
if torch.cuda.is_available():
    x = torch.randn(100, 100).cuda()
    y = torch.mm(x, x.t())
    print("âœ… GPU è®¡ç®—æ­£å¸¸")
else:
    print("âŒ GPU ä¸å¯ç”¨")
```

## ğŸ“‹ æ”¯æŒçš„ AMD GPU

### å®Œå…¨æ”¯æŒ
- AMD Radeon RX 6000 ç³»åˆ— (RDNA2)
- AMD Radeon RX 7000 ç³»åˆ— (RDNA3)
- AMD Instinct MI100/MI200 ç³»åˆ—

### éƒ¨åˆ†æ”¯æŒ
- AMD Radeon RX 5000 ç³»åˆ— (RDNA1)
- è¾ƒè€çš„ GCN æ¶æ„ GPU

### æ£€æŸ¥ GPU æ¶æ„
```bash
rocminfo | grep "Name:"
rocminfo | grep "Compute Unit:"
```

## ğŸ› ï¸ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¯å¢ƒå˜é‡ä¼˜åŒ–
```bash
export HSA_FORCE_FINE_GRAIN_PCIE=1
export HIP_VISIBLE_DEVICES=0
export PYTORCH_HIP_ALLOC_CONF=max_split_size_mb:128
```

### 2. æ¨¡å‹é…ç½®ä¼˜åŒ–
```python
# å‡å°‘å†…å­˜ä½¿ç”¨
agent = TxAgent(
    model_name,
    rag_model_name,
    enable_summary=False,
    avoid_repeat=True,  # å¯ç”¨é‡å¤é¿å…
    step_rag_num=5      # å‡å°‘ RAG æ­¥æ•°
)
```

### 3. æ¨ç†å‚æ•°ä¼˜åŒ–
```python
response = agent.run_multistep_agent(
    question,
    temperature=0.3,
    max_new_tokens=512,  # å‡å°‘ç”Ÿæˆé•¿åº¦
    max_token=45120,     # å‡å°‘æœ€å¤§ä»¤ç‰Œæ•°
    max_round=10         # å‡å°‘æ¨ç†è½®æ•°
)
```

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°å…¶ä»–é—®é¢˜ï¼š

1. **æ£€æŸ¥æ—¥å¿—**: æŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
2. **ç¯å¢ƒä¿¡æ¯**: è¿è¡Œ `python amd_gpu_config.py` è·å–ç¯å¢ƒæŠ¥å‘Š
3. **ç¤¾åŒºæ”¯æŒ**: 
   - ROCm GitHub: https://github.com/RadeonOpenCompute/ROCm
   - PyTorch ROCm: https://pytorch.org/get-started/locally/
   - vLLM Issues: https://github.com/vllm-project/vllm/issues

## ğŸ”„ ç‰ˆæœ¬å…¼å®¹æ€§

| ç»„ä»¶ | æ¨èç‰ˆæœ¬ | ROCm ç‰ˆæœ¬ |
|------|----------|-----------|
| ROCm | 5.7+ | 5.7.0 |
| PyTorch | 2.0+ | rocm5.7 |
| vLLM | 0.3.0+ | æœ€æ–° |
| Python | 3.8+ | - |

å®šæœŸæ›´æ–°è¿™äº›ç»„ä»¶ä»¥è·å¾—æœ€ä½³æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚
